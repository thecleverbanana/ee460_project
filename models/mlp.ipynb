{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5bea353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "sys.path.append(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22a5d8d",
   "metadata": {},
   "source": [
    "## Load and Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7399790e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.loader import load_data_with_logReturn\n",
    "\n",
    "data_clean = load_data_with_logReturn(\"../stocks/AAPL.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "612d1b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 11182 entries, 1980-12-22 to 2025-05-02\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Adj Close       11182 non-null  float64\n",
      " 1   Close           11182 non-null  float64\n",
      " 2   High            11182 non-null  float64\n",
      " 3   Low             11182 non-null  float64\n",
      " 4   Open            11182 non-null  float64\n",
      " 5   Volume          11182 non-null  int64  \n",
      " 6   LogReturn       11182 non-null  float64\n",
      " 7   LogReturn_Lag1  11182 non-null  float64\n",
      " 8   LogReturn_Lag2  11182 non-null  float64\n",
      " 9   LogReturn_Lag3  11182 non-null  float64\n",
      " 10  LogReturn_Lag4  11182 non-null  float64\n",
      " 11  LogReturn_Lag5  11182 non-null  float64\n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 1.1 MB\n"
     ]
    }
   ],
   "source": [
    "data_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aed0fe7",
   "metadata": {},
   "source": [
    "Feature Engineering for the input layer. Now set the slide window size for 10 days, i.e 10x10 = 100 neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "311aa43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_Dataset(Dataset):\n",
    "    def __init__(self, df, window, stride):\n",
    "        self.window = window\n",
    "        self.stride = stride\n",
    "        self.X, self.y = self.create_features(df)\n",
    "\n",
    "    def create_features(self, df):\n",
    "        X_list, y_list = [], []\n",
    "        for i in range(self.window, len(df) - 1, self.stride):\n",
    "            window_data = df.iloc[i-self.window:i][[\n",
    "                \"Open\", \"High\", \"Low\", \"Close\", \"Volume\",\n",
    "                \"LogReturn_Lag1\", \"LogReturn_Lag2\", \"LogReturn_Lag3\", \"LogReturn_Lag4\", \"LogReturn_Lag5\"\n",
    "            ]].values  \n",
    "\n",
    "            flat_window = window_data.flatten()\n",
    "            X_list.append(flat_window) \n",
    "            y_list.append(df[\"LogReturn\"].iloc[i+1])  # or LogReturn, etc.\n",
    "\n",
    "        X_array = np.array(X_list)\n",
    "        y_array = np.array(y_list)\n",
    "        return torch.tensor(X_array, dtype=torch.float32), torch.tensor(y_array, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8ee9d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "batch_size = 8\n",
    "window = 50\n",
    "stride=50\n",
    "\n",
    "# Normailize data\n",
    "feature_cols = [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\",\n",
    "                \"LogReturn_Lag1\", \"LogReturn_Lag2\", \"LogReturn_Lag3\",\n",
    "                \"LogReturn_Lag4\", \"LogReturn_Lag5\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data_clean_scaler = data_clean.copy()\n",
    "data_clean_scaler[feature_cols] = scaler.fit_transform(data_clean_scaler[feature_cols])\n",
    "\n",
    "# Assume data_clean is already prepared\n",
    "dataset = MLP_Dataset(data_clean_scaler, window, stride)\n",
    "\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4ce7833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices_by_date_range(sample_end_dates, start_date, end_date, name=\"\"):\n",
    "    indices = [\n",
    "        i for i, date in enumerate(sample_end_dates)\n",
    "        if start_date <= date <= end_date\n",
    "    ]\n",
    "    if len(indices) == 0:\n",
    "        print(f\"[Warning] No {name} samples in interval: {start_date.date()} ~ {end_date.date()}\")\n",
    "    return indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a636d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.4863, -0.4862, -0.4861, -0.4861, -0.8263,  2.0773,  0.9898,  0.8432,\n",
       "         -2.7263, -1.9227, -0.4861, -0.4861, -0.4860, -0.4860, -0.7976,  1.6617,\n",
       "          2.0771,  0.9897,  0.8432, -2.7256, -0.4860, -0.4860, -0.4858, -0.4859,\n",
       "         -0.7944,  1.4422,  1.6616,  2.0770,  0.9896,  0.8432, -0.4858, -0.4858,\n",
       "         -0.4856, -0.4856, -0.7718,  1.7954,  1.4421,  1.6615,  2.0766,  0.9896,\n",
       "         -0.4857, -0.4857, -0.4855, -0.4856, -0.6594,  3.1078,  1.7952,  1.4420,\n",
       "          1.6612,  2.0764, -0.4858, -0.4858, -0.4856, -0.4857, -0.7320,  0.4723,\n",
       "          3.1076,  1.7951,  1.4417,  1.6611, -0.4859, -0.4859, -0.4857, -0.4857,\n",
       "         -0.8311, -0.8964,  0.4722,  3.1074,  1.7948,  1.4417, -0.4858, -0.4858,\n",
       "         -0.4857, -0.4857, -0.8732, -1.0481, -0.8965,  0.4721,  3.1066,  1.7946,\n",
       "         -0.4859, -0.4859, -0.4857, -0.4858, -0.8311,  0.3638, -1.0481, -0.8965,\n",
       "          0.4722,  3.1063, -0.4860, -0.4860, -0.4859, -0.4859, -0.8029, -0.8032,\n",
       "          0.3637, -1.0482, -0.8959,  0.4723, -0.4861, -0.4861, -0.4860, -0.4860,\n",
       "         -0.7715, -1.6363, -0.8033,  0.3637, -1.0476, -0.8956, -0.4862, -0.4862,\n",
       "         -0.4860, -0.4861, -0.8189, -1.5690, -1.6363, -0.8033,  0.3638, -1.0472,\n",
       "         -0.4861, -0.4861, -0.4859, -0.4859, -0.8737, -0.7490, -1.5690, -1.6364,\n",
       "         -0.8028,  0.3639, -0.4861, -0.4861, -0.4859, -0.4859, -0.8671,  1.8320,\n",
       "         -0.7491, -1.5690, -1.6356, -0.8025, -0.4862, -0.4862, -0.4860, -0.4860,\n",
       "         -0.8691, -0.3030,  1.8318, -0.7491, -1.5683, -1.6351, -0.4862, -0.4862,\n",
       "         -0.4860, -0.4860, -0.8952, -1.3084, -0.3031,  1.8317, -0.7486, -1.5678,\n",
       "         -0.4861, -0.4861, -0.4859, -0.4860, -0.8959,  0.1213, -1.3084, -0.3031,\n",
       "          1.8313, -0.7483, -0.4861, -0.4861, -0.4860, -0.4860, -0.8979,  0.6927,\n",
       "          0.1212, -1.3084, -0.3028,  1.8312, -0.4860, -0.4860, -0.4858, -0.4858,\n",
       "         -0.8137, -0.3086,  0.6926,  0.1211, -1.3077, -0.3025, -0.4861, -0.4861,\n",
       "         -0.4859, -0.4859, -0.8480,  2.0589, -0.3087,  0.6925,  0.1214, -1.3073,\n",
       "         -0.4860, -0.4860, -0.4858, -0.4859, -0.8904, -1.1193,  2.0588, -0.3087,\n",
       "          0.6926,  0.1215, -0.4860, -0.4860, -0.4858, -0.4858, -0.8317,  0.6649,\n",
       "         -1.1193,  2.0586, -0.3084,  0.6926, -0.4860, -0.4860, -0.4858, -0.4859,\n",
       "         -0.9044,  0.3831,  0.6648, -1.1194,  2.0582, -0.3081, -0.4860, -0.4860,\n",
       "         -0.4859, -0.4859, -0.8643, -0.1589,  0.3830,  0.6647, -1.1187,  2.0581,\n",
       "         -0.4860, -0.4860, -0.4859, -0.4859, -0.8671, -0.5694, -0.1589,  0.3829,\n",
       "          0.6648, -1.1184, -0.4861, -0.4861, -0.4860, -0.4860, -0.8538, -0.2998,\n",
       "         -0.5694, -0.1590,  0.3831,  0.6648, -0.4862, -0.4862, -0.4861, -0.4861,\n",
       "         -0.8067, -1.1497, -0.2998, -0.5695, -0.1587,  0.3832, -0.4863, -0.4863,\n",
       "         -0.4862, -0.4862, -0.7999, -1.3347, -1.1498, -0.2999, -0.5690, -0.1585,\n",
       "         -0.4865, -0.4865, -0.4863, -0.4864, -0.8669, -2.0075, -1.3348, -1.1498,\n",
       "         -0.2995, -0.5688, -0.4864, -0.4864, -0.4863, -0.4863, -0.8807, -2.1248,\n",
       "         -2.0075, -1.3348, -1.1491, -0.2993, -0.4863, -0.4863, -0.4862, -0.4862,\n",
       "         -0.8547,  1.2838, -2.1248, -2.0075, -1.3341, -1.1488, -0.4863, -0.4863,\n",
       "         -0.4862, -0.4862, -0.9143,  1.2373,  1.2837, -2.1248, -2.0066, -1.3337,\n",
       "         -0.4863, -0.4863, -0.4862, -0.4862, -0.8965, -0.0238,  1.2372,  1.2836,\n",
       "         -2.1238, -2.0061, -0.4864, -0.4864, -0.4863, -0.4863, -0.8879,  0.1308,\n",
       "         -0.0238,  1.2371,  1.2835, -2.1233, -0.4865, -0.4864, -0.4863, -0.4863,\n",
       "         -0.8831, -1.9241,  0.1307, -0.0239,  1.2370,  1.2834, -0.4865, -0.4865,\n",
       "         -0.4864, -0.4864, -0.8966, -0.0238, -1.9241,  0.1306, -0.0236,  1.2369,\n",
       "         -0.4865, -0.4865, -0.4864, -0.4864, -0.8944, -1.1812, -0.0238, -1.9241,\n",
       "          0.1308, -0.0234, -0.4866, -0.4866, -0.4864, -0.4865, -0.9046, -0.3618,\n",
       "         -1.1813, -0.0239, -1.9232,  0.1310, -0.4865, -0.4865, -0.4864, -0.4864,\n",
       "         -0.9013, -0.8825, -0.3619, -1.1813, -0.0236, -1.9227, -0.4865, -0.4864,\n",
       "         -0.4863, -0.4863, -0.8804,  0.8350, -0.8826, -0.3619, -1.1806, -0.0234,\n",
       "         -0.4866, -0.4866, -0.4864, -0.4865, -0.8713,  1.4718,  0.8349, -0.8826,\n",
       "         -0.3616, -1.1803, -0.4867, -0.4867, -0.4865, -0.4866, -0.8651, -2.2046,\n",
       "          1.4716,  0.8348, -0.8820, -0.3613, -0.4867, -0.4867, -0.4865, -0.4865,\n",
       "         -0.8958, -1.9797, -2.2046,  1.4715,  0.8348, -0.8817, -0.4867, -0.4867,\n",
       "         -0.4866, -0.4866, -0.8872,  0.5205, -1.9797, -2.2046,  1.4713,  0.8348,\n",
       "         -0.4866, -0.4866, -0.4865, -0.4865, -0.8797, -1.3069,  0.5204, -1.9797,\n",
       "         -2.2036,  1.4712, -0.4866, -0.4866, -0.4864, -0.4865, -0.9056,  2.1482,\n",
       "         -1.3069,  0.5203, -1.9788, -2.2031, -0.4865, -0.4865, -0.4864, -0.4864,\n",
       "         -0.8938,  0.4991,  2.1481, -1.3069,  0.5204, -1.9783, -0.4865, -0.4865,\n",
       "         -0.4863, -0.4864, -0.9028,  1.1673,  0.4990,  2.1480, -1.3062,  0.5205,\n",
       "         -0.4865, -0.4865, -0.4864, -0.4864, -0.8896,  0.1431,  1.1672,  0.4989,\n",
       "          2.1475, -1.3058, -0.4865, -0.4865, -0.4864, -0.4864, -0.8970, -0.5268,\n",
       "          0.1430,  1.1671,  0.4990,  2.1473]),\n",
       " tensor(-0.0097))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b92abf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all timestamps from the original DataFrame\n",
    "all_dates = data_clean.index.tolist()\n",
    "\n",
    "# Determine the ending date of each sample (starts from index=10 due to window)\n",
    "sample_end_dates = [\n",
    "    all_dates[i] for i in range(window, len(data_clean) - 1, stride)\n",
    "]  # offset by window size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c677ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define date boundaries for each split\n",
    "train_val_test_start_date = pd.Timestamp(\"1980-01-01\")\n",
    "train_val_test_end_date = pd.Timestamp(\"2024-12-31\")\n",
    "\n",
    "main_indices = get_indices_by_date_range(\n",
    "    sample_end_dates, train_val_test_start_date, train_val_test_end_date, \"train/val/test\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3172973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 110,\n",
       " 111,\n",
       " 112,\n",
       " 113,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 121,\n",
       " 122,\n",
       " 123,\n",
       " 124,\n",
       " 125,\n",
       " 126,\n",
       " 127,\n",
       " 128,\n",
       " 129,\n",
       " 130,\n",
       " 131,\n",
       " 132,\n",
       " 133,\n",
       " 134,\n",
       " 135,\n",
       " 136,\n",
       " 137,\n",
       " 138,\n",
       " 139,\n",
       " 140,\n",
       " 141,\n",
       " 142,\n",
       " 143,\n",
       " 144,\n",
       " 145,\n",
       " 146,\n",
       " 147,\n",
       " 148,\n",
       " 149,\n",
       " 150,\n",
       " 151,\n",
       " 152,\n",
       " 153,\n",
       " 154,\n",
       " 155,\n",
       " 156,\n",
       " 157,\n",
       " 158,\n",
       " 159,\n",
       " 160,\n",
       " 161,\n",
       " 162,\n",
       " 163,\n",
       " 164,\n",
       " 165,\n",
       " 166,\n",
       " 167,\n",
       " 168,\n",
       " 169,\n",
       " 170,\n",
       " 171,\n",
       " 172,\n",
       " 173,\n",
       " 174,\n",
       " 175,\n",
       " 176,\n",
       " 177,\n",
       " 178,\n",
       " 179,\n",
       " 180,\n",
       " 181,\n",
       " 182,\n",
       " 183,\n",
       " 184,\n",
       " 185,\n",
       " 186,\n",
       " 187,\n",
       " 188,\n",
       " 189,\n",
       " 190,\n",
       " 191,\n",
       " 192,\n",
       " 193,\n",
       " 194,\n",
       " 195,\n",
       " 196,\n",
       " 197,\n",
       " 198,\n",
       " 199,\n",
       " 200,\n",
       " 201,\n",
       " 202,\n",
       " 203,\n",
       " 204,\n",
       " 205,\n",
       " 206,\n",
       " 207,\n",
       " 208,\n",
       " 209,\n",
       " 210,\n",
       " 211,\n",
       " 212,\n",
       " 213,\n",
       " 214,\n",
       " 215,\n",
       " 216,\n",
       " 217,\n",
       " 218,\n",
       " 219,\n",
       " 220]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a988a61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(main_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcfc1b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(main_indices)\n",
    "train_end = int(total * 0.7)\n",
    "val_end = int(total * 0.85)\n",
    "\n",
    "train_indices = main_indices[:train_end]\n",
    "val_indices = main_indices[train_end:val_end]\n",
    "test_indices = main_indices[val_end:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a479a6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(main_indices)\n",
    "train_end = int(total * 0.7)\n",
    "val_end = int(total * 0.85)\n",
    "\n",
    "train_indices = main_indices[:train_end]\n",
    "val_indices = main_indices[train_end:val_end]\n",
    "test_indices = main_indices[val_end:]\n",
    "\n",
    "# Create subsets\n",
    "train_set = Subset(dataset, train_indices)\n",
    "val_set = Subset(dataset, val_indices)\n",
    "test_set = Subset(dataset, test_indices)\n",
    "\n",
    "y_train = data_clean[\"LogReturn\"].iloc[[window + i + 1 for i in train_indices]].values\n",
    "y_val   = data_clean[\"LogReturn\"].iloc[[window + i + 1 for i in val_indices]].values\n",
    "y_test  = data_clean[\"LogReturn\"].iloc[[window + i + 1 for i in test_indices]].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba24ab3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[168,\n",
       " 17,\n",
       " 49,\n",
       " 147,\n",
       " 92,\n",
       " 158,\n",
       " 160,\n",
       " 75,\n",
       " 141,\n",
       " 20,\n",
       " 96,\n",
       " 31,\n",
       " 137,\n",
       " 117,\n",
       " 11,\n",
       " 67,\n",
       " 198,\n",
       " 88,\n",
       " 91,\n",
       " 24,\n",
       " 97,\n",
       " 202,\n",
       " 211,\n",
       " 86,\n",
       " 201,\n",
       " 39,\n",
       " 186,\n",
       " 87,\n",
       " 205,\n",
       " 178,\n",
       " 40,\n",
       " 1,\n",
       " 71]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c0b823e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2203097e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 223\n",
      "Input feature shape: torch.Size([500])\n",
      "Target value: tensor(-0.0097)\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of samples:\", len(dataset))\n",
    "print(\"Input feature shape:\", dataset[0][0].shape)\n",
    "print(\"Target value:\", dataset[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb285bc8",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f8c385",
   "metadata": {},
   "source": [
    "Define MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15acfeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 256)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.dropout3 = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.fc4 = nn.Linear(64, 32)\n",
    "        self.relu4 = nn.ReLU()\n",
    "\n",
    "        self.fc5 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.dropout3(x)\n",
    "\n",
    "        x = self.fc4(x)\n",
    "        x = self.relu4(x)\n",
    "\n",
    "        x = self.fc5(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6d3e00",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5b61a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "model = MLP(input_size=train_set.dataset.X.shape[1]).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56e2165d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.002065, Val Loss: 0.000914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 0.001289, Val Loss: 0.000939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 0.001200, Val Loss: 0.000669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.001152, Val Loss: 0.000699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 0.000774, Val Loss: 0.000624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Loss: 0.000637, Val Loss: 0.000685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Loss: 0.000520, Val Loss: 0.000985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 0.000877, Val Loss: 0.000564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train Loss: 0.000495, Val Loss: 0.000639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 0.000403, Val Loss: 0.000653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Train Loss: 0.000370, Val Loss: 0.000576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Train Loss: 0.000371, Val Loss: 0.000669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Train Loss: 0.000371, Val Loss: 0.000682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Train Loss: 0.000363, Val Loss: 0.000637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Train Loss: 0.000256, Val Loss: 0.000778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Train Loss: 0.000253, Val Loss: 0.000742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Train Loss: 0.000298, Val Loss: 0.000613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Train Loss: 0.000308, Val Loss: 0.000685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Train Loss: 0.000190, Val Loss: 0.000737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Train Loss: 0.000193, Val Loss: 0.000787\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "epochs = 20\n",
    "best_val_loss = float(\"inf\")\n",
    "best_model_state = None\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}\", leave=False)\n",
    "\n",
    "    for X_batch, y_batch in progress_bar:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device).unsqueeze(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * X_batch.size(0)\n",
    "        avg_train_loss = train_loss / len(train_loader.dataset)\n",
    "        progress_bar.set_postfix(loss=avg_train_loss)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X_val_batch, y_val_batch in val_loader:\n",
    "            X_val_batch, y_val_batch = X_val_batch.to(device), y_val_batch.to(device).unsqueeze(1)\n",
    "            val_outputs = model(X_val_batch)\n",
    "            loss = criterion(val_outputs, y_val_batch)\n",
    "            val_loss += loss.item() * X_val_batch.size(0)\n",
    "    avg_val_loss = val_loss / len(val_loader.dataset)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {avg_train_loss:.6f}, Val Loss: {avg_val_loss:.6f}\")\n",
    "\n",
    "    if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                best_model_state = model.state_dict()\n",
    "\n",
    "if best_model_state is not None:\n",
    "            model.load_state_dict(best_model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa718c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Train R2': -0.2750952700141267, 'Val R2': -0.03864725472460262, 'Test R2': -0.45921357427607834, 'Train RMSE': 0.03623422470592378, 'Val RMSE': 0.04631085610203369, 'Test RMSE': 0.03569256635131}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, root_mean_squared_error\n",
    "\n",
    "if best_model_state is not None:\n",
    "    model.load_state_dict(best_model_state)\n",
    "else:\n",
    "    print(\"[Warning] best_model_state is None — using current model weights.\")\n",
    "\n",
    "model.eval()\n",
    "preds_train, preds_val, preds_test = [], [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, _ in train_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_pred = model(X_batch)\n",
    "        preds_train.extend(y_pred.cpu().numpy().flatten())\n",
    "\n",
    "    for X_batch, _ in val_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_pred = model(X_batch)\n",
    "        preds_val.extend(y_pred.cpu().numpy().flatten())\n",
    "\n",
    "    for X_batch, _ in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_pred = model(X_batch)\n",
    "        preds_test.extend(y_pred.cpu().numpy().flatten())\n",
    "\n",
    "y_train_pred = np.array(preds_train)\n",
    "y_val_pred   = np.array(preds_val)\n",
    "y_test_pred  = np.array(preds_test)\n",
    "\n",
    "\n",
    "# Print evaluation metrics\n",
    "print({\n",
    "    \"Train R2\": r2_score(y_train, y_train_pred),\n",
    "    \"Val R2\": r2_score(y_val, y_val_pred),\n",
    "    \"Test R2\": r2_score(y_test, y_test_pred),\n",
    "    \"Train RMSE\": root_mean_squared_error(y_train, y_train_pred),\n",
    "    \"Val RMSE\": root_mean_squared_error(y_val, y_val_pred),\n",
    "    \"Test RMSE\": root_mean_squared_error(y_test, y_test_pred),\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ca1fb7",
   "metadata": {},
   "source": [
    "Trading Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916fa2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_world_start_date = pd.Timestamp(\"2025-01-01\")\n",
    "real_world_end_date = pd.Timestamp(\"2025-05-02\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6c5169",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_world_indices = get_indices_by_date_range(\n",
    "            sample_end_dates,\n",
    "            real_world_start_date,\n",
    "            real_world_end_date,\n",
    "            name=\"Real_World\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d879f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_world_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975656e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_world_loader = DataLoader(\n",
    "            Subset(dataset, real_world_indices), batch_size=batch_size\n",
    "        )\n",
    "\n",
    "X_real = data_clean.iloc[[window + i + 1 for i in real_world_indices]]\n",
    "y_real_world = [data_clean[\"LogReturn\"].iloc[window + i + 1] for i in real_world_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fee3bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.eval import evaluate_strategy_performance_real_world,calculate_average_pnl\n",
    "\n",
    "returns, capital, positions = evaluate_strategy_performance_real_world(\n",
    "            y_real_world,\n",
    "            y_real_pred,\n",
    "        )\n",
    "\n",
    "pnl_result = calculate_average_pnl(positions, y_real_world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f205ac7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plotter import long_short_position_graph\n",
    "\n",
    "result = {\n",
    "            **returns,\n",
    "            **capital,\n",
    "            \"Average PnL\": pnl_result[\"average_pnl\"],\n",
    "            \"Average PnL (%)\": pnl_result[\"average_pnl_percent\"]\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5014ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_real_true = pd.Series(y_real_world, index=X_real.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dcf42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = long_short_position_graph(X_real, y_real_true, y_real_pred, positions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1107184e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Long/Short markers\n",
    "long_signals = (positions == 1)\n",
    "short_signals = (positions == -1)\n",
    "\n",
    "# Dates and data alignment\n",
    "test_dates = y_real_true.index\n",
    "plot_dates = test_dates[1:]\n",
    "\n",
    "P_t = X_real.Close.iloc[:-1].values\n",
    "r_hat_t_plus_1 = y_test_pred[1:]\n",
    "P_hat_t_plus_1 = P_t * np.exp(r_hat_t_plus_1)\n",
    "\n",
    "# Ensure same length across all series\n",
    "min_len = min(len(plot_dates), len(P_hat_t_plus_1))\n",
    "plot_dates = plot_dates[:min_len]\n",
    "P_hat_t_plus_1 = P_hat_t_plus_1[:min_len]\n",
    "actual_prices = X_real.Close.values[:min_len]\n",
    "\n",
    "long_signals = long_signals[1:][:min_len]\n",
    "short_signals = short_signals[1:][:min_len]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(plot_dates, actual_prices, label=\"Actual Price\", alpha=0.7)\n",
    "plt.plot(plot_dates, P_hat_t_plus_1, label=\"Reconstructed Price from Predicted Returns\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "plt.scatter(plot_dates[long_signals], actual_prices[long_signals], marker='^', color='green', label='Long Entry', zorder=5)\n",
    "plt.scatter(plot_dates[short_signals], actual_prices[short_signals], marker='v', color='red', label='Short Entry', zorder=5)\n",
    "\n",
    "plt.title(\"AAPL: Actual vs Reconstructed Price (from Predicted Log Returns)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price (USD)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ee460",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
